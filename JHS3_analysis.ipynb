{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating trigger times for JHS3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import zscore\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "participantNumber = [10,11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "                     21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
    "                     31, 32, 33, 34, 35]\n",
    "\n",
    "\n",
    "blockNumber = [1, 2, 3, 4]\n",
    "sample = [\"Silk\", \"Hessian\"]\n",
    "    \n",
    "freq = 20 # in Hz\n",
    "timeSteps = 1/freq\n",
    "\n",
    "baselineLen, primeLen, trialLen = 4, 1, 4\n",
    "\n",
    "baselineInterval, primeInterval, trialInterval = baselineLen*freq, primeLen*freq, trialLen*freq\n",
    "baselinePrimeInterval, totalTrialInterval = baselineInterval+primeInterval, trialInterval+baselinePrimeInterval\n",
    "\n",
    "maxSampleRejection = 10 #value is percent\n",
    "minimumSampleWholeTrial, minimumSampleTrial, minimumSampleBaseline = totalTrialInterval-((totalTrialInterval/100)*maxSampleRejection), (trialInterval/100)*maxSampleRejection, (baselineInterval/100)*maxSampleRejection\n",
    "\n",
    "rejectTrigger, acceptTrigger = 903, 72\n",
    "\n",
    "SD = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read compilation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\jlh94\\FORCE PLATE SOFTWARE (21Nov2020)\\JHS3_Processed_100Hz\\\\\"\n",
    "fileName  = \"BlockAveragesCompilation(\" \n",
    "fileType = \".csv\"\n",
    "\n",
    "df = pd.read_csv(path + fileName + str(freq) + '.0Hz)' + fileType)\n",
    "\n",
    "df.rename(columns={ df.columns[6]: \"Study_Block\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only relevent columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={ 'X_Corr (mm)': \"X_Corr\", 'Y_Corr (mm)': 'Y_Corr', \n",
    "                        'Velocity_X (mm/s)': 'Velocity_X', 'Velocity_Y (mm/s)': 'Velocity_Y',\n",
    "                       'Speed (mm/s)': 'Speed', 'Friction (N)': 'Friction'})\n",
    "df = df[['Participant', 'Study_Block','Sample', 'Time (s)','Trigger', \n",
    "         'FzLocallyFinite', 'Speed', 'Friction']]\n",
    "# 'X_Corr', 'Y_Corr','Velocity_X',Velocity_Y', "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through data to identify x co-ordinate where new trigger will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTriggerRelTime = pd.DataFrame() #create an empty dataframe where we will append our data\n",
    "dfERDTriggers = pd.DataFrame()\n",
    "\n",
    "for p in participantNumber:\n",
    "    dfP = df[df['Participant'] == p]  # when value in 'Participant' column is equal to the participant value in loop\n",
    "    for b in blockNumber:\n",
    "        dfB = dfP[dfP['Study_Block'] == b] # when value in 'Study_block' column is equal to the block value in loop\n",
    "        for s in sample:\n",
    "            dfS = dfB[dfB['Sample'] == s].reset_index(drop=True)# when value in 'Sample' column is equal to the smaple value in loop\n",
    "            \n",
    "            num =[] # create empty array\n",
    "            for ind in dfS.index: #loop through the data frame\n",
    "                if dfS.Trigger[ind] > 1.3: # identify instances when the trigger value is greater than 1.3\n",
    "                    if  len(num) == 0: # if the num list is empty\n",
    "                        num.append(ind) # appened the index value to the empty array that was previously created \n",
    "                    else: # if the num list is not empty\n",
    "                        if ind>(num[-1]+trialInterval): # if the ind value is greater than the last num value plus the time interval of the trial in samples\n",
    "                            num.append(ind) # appened the index value to the empty array that was previously created \n",
    "                            \n",
    "            x = pd.DataFrame()\n",
    "            for n in num: \n",
    "                dfEpoch= dfS[n-baselinePrimeInterval:n+trialInterval].reset_index(drop=True)\n",
    "                dfFiltered = dfEpoch[dfEpoch['FzLocallyFinite'] == 1] # only look at the rows where 'FzLocallyFinite' is equal to 1, not 0 \n",
    "                meanBaseline, meanTrial = dfFiltered[0:baselineInterval].Speed.mean(), dfFiltered[baselinePrimeInterval:totalTrialInterval].Speed.mean()\n",
    "                x = x.append({'meanBaseline': meanBaseline, 'meanTrial': meanTrial},ignore_index=True)\n",
    "            \n",
    "            x['baselineZscore'], x['trialZscore'] = abs(stats.zscore(x.meanBaseline)), abs(stats.zscore(x.meanTrial))\n",
    "            x.loc[x.baselineZscore >= SD, 'meanBaseline'] = np.nan\n",
    "            x.loc[x.trialZscore >= SD, 'meanTrial'] = np.nan\n",
    "            baselineMax, trialMin = x.meanBaseline.max(),x.meanTrial.min()\n",
    "            \n",
    "            for e in range(len(num)): \n",
    "                dfEpoch= dfS[num[e]-baselinePrimeInterval:num[e]+trialInterval].reset_index(drop=True)\n",
    "                dfEpoch.insert(3, \"RelativeTime\", np.arange(start=(minusTriggerTime*-1), stop=trialLen, step=timeSteps), True) # insert a column with the relative time from the trigger\n",
    "                dfEpoch.insert(3, \"Trial\", e+1) # insert a column with the relative time from the trigger\n",
    "                dfFiltered = dfEpoch[dfEpoch['FzLocallyFinite'] == 1] # only look at the rows where 'FzLocallyFinite' is equal to 1, not 0 \n",
    "                meanBaseline, meanTrial = dfFiltered[0:baselineInterval].Speed.mean(), dfFiltered[baselinePrimeInterval:totalTrialInterval].Speed.mean()\n",
    "                dfFiltered = dfFiltered.drop(columns=[\"FzLocallyFinite\", \"Time (s)\"])\n",
    "                \n",
    "                #The loop below rejects trials where there are fewer than 75% of samples from baseline start to the end of the trial were there was sufficient force to perform calculations\n",
    "                if ((len(dfFiltered)) < minimumSampleWholeTrial): #skip over dataframes that have less than 75% of samples\n",
    "                    dfTriggerRelTime = dfTriggerRelTime.append({'Participant': p, 'Study_Block': b, 'Sample': s, 'Trial': (e+1),'Relative Time': np.nan,\n",
    "                                                'Trigger': rejectTrigger, 'Speed': np.nan, 'Friction': np.nan}\n",
    "                                               ,ignore_index=True)\n",
    "                    dfERDTriggers = dfERDTriggers.append({'Participant': p, 'Study_Block': b, 'Sample': s, 'Trial': (e+1),\n",
    "                                                          'Trigger': rejectTrigger},ignore_index=True)\n",
    "                    \n",
    "                elif meanBaseline > baselineMax or meanTrial<trialMin:\n",
    "                    dfTriggerRelTime = dfTriggerRelTime.append({'Participant': p, 'Study_Block': b, 'Sample': s, 'Trial': (e+1),'Relative Time': np.nan,\n",
    "                                                'Trigger': rejectTrigger, 'Speed': np.nan, 'Friction': np.nan}\n",
    "                                               ,ignore_index=True)\n",
    "                                                                \n",
    "                    dfERDTriggers = dfERDTriggers.append({'Participant': p, 'Study_Block': b, 'Sample': s, 'Trial': (e+1),\n",
    "                                                'Trigger': rejectTrigger},ignore_index=True)\n",
    "                    \n",
    "                else: \n",
    "                    dfTriggerRelTime = dfTriggerRelTime.append(dfFiltered)\n",
    "                    dfERDTriggers = dfERDTriggers.append({'Participant': p, 'Study_Block': b, 'Sample': s, 'Trial': (e+1),\n",
    "                                                'Trigger': acceptTrigger},ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Participant   Sample  Study_Block  Trial  Trigger\n",
      "0           10.0     Silk          1.0    1.0     72.0\n",
      "1           10.0     Silk          1.0    2.0     72.0\n",
      "2           10.0     Silk          1.0    3.0     72.0\n",
      "3           10.0     Silk          1.0    4.0     72.0\n",
      "4           10.0     Silk          1.0    5.0     72.0\n",
      "5           10.0     Silk          1.0    6.0    903.0\n",
      "6           10.0     Silk          1.0    7.0     72.0\n",
      "7           10.0     Silk          1.0    8.0     72.0\n",
      "8           10.0     Silk          1.0    9.0     72.0\n",
      "9           10.0     Silk          1.0   10.0     72.0\n",
      "10          10.0     Silk          1.0   11.0     72.0\n",
      "11          10.0     Silk          1.0   12.0     72.0\n",
      "12          10.0     Silk          1.0   13.0     72.0\n",
      "13          10.0     Silk          1.0   14.0     72.0\n",
      "14          10.0     Silk          1.0   15.0     72.0\n",
      "15          10.0     Silk          1.0   16.0     72.0\n",
      "16          10.0     Silk          1.0   17.0     72.0\n",
      "17          10.0     Silk          1.0   18.0     72.0\n",
      "18          10.0     Silk          1.0   19.0     72.0\n",
      "19          10.0     Silk          1.0   20.0     72.0\n",
      "20          10.0     Silk          1.0   21.0     72.0\n",
      "21          10.0     Silk          1.0   22.0     72.0\n",
      "22          10.0     Silk          1.0   23.0     72.0\n",
      "23          10.0     Silk          1.0   24.0     72.0\n",
      "24          10.0     Silk          1.0   25.0     72.0\n",
      "25          10.0     Silk          1.0   26.0     72.0\n",
      "26          10.0     Silk          1.0   27.0     72.0\n",
      "27          10.0     Silk          1.0   28.0    903.0\n",
      "28          10.0     Silk          1.0   29.0     72.0\n",
      "29          10.0     Silk          1.0   30.0     72.0\n",
      "..           ...      ...          ...    ...      ...\n",
      "330         10.0  Hessian          4.0   13.0     72.0\n",
      "331         10.0  Hessian          4.0   14.0     72.0\n",
      "332         10.0  Hessian          4.0   15.0     72.0\n",
      "333         10.0  Hessian          4.0   16.0     72.0\n",
      "334         10.0  Hessian          4.0   17.0     72.0\n",
      "335         10.0  Hessian          4.0   18.0     72.0\n",
      "336         10.0  Hessian          4.0   19.0     72.0\n",
      "337         10.0  Hessian          4.0   20.0    903.0\n",
      "338         10.0  Hessian          4.0   21.0    903.0\n",
      "339         10.0  Hessian          4.0   22.0     72.0\n",
      "340         10.0  Hessian          4.0   23.0     72.0\n",
      "341         10.0  Hessian          4.0   24.0     72.0\n",
      "342         10.0  Hessian          4.0   25.0     72.0\n",
      "343         10.0  Hessian          4.0   26.0    903.0\n",
      "344         10.0  Hessian          4.0   27.0     72.0\n",
      "345         10.0  Hessian          4.0   28.0     72.0\n",
      "346         10.0  Hessian          4.0   29.0     72.0\n",
      "347         10.0  Hessian          4.0   30.0    903.0\n",
      "348         10.0  Hessian          4.0   31.0     72.0\n",
      "349         10.0  Hessian          4.0   32.0     72.0\n",
      "350         10.0  Hessian          4.0   33.0     72.0\n",
      "351         10.0  Hessian          4.0   34.0     72.0\n",
      "352         10.0  Hessian          4.0   35.0     72.0\n",
      "353         10.0  Hessian          4.0   36.0     72.0\n",
      "354         10.0  Hessian          4.0   37.0    903.0\n",
      "355         10.0  Hessian          4.0   38.0     72.0\n",
      "356         10.0  Hessian          4.0   39.0     72.0\n",
      "357         10.0  Hessian          4.0   40.0     72.0\n",
      "358         10.0  Hessian          4.0   41.0     72.0\n",
      "359         10.0  Hessian          4.0   42.0     72.0\n",
      "\n",
      "[360 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#print(dfTriggerRelTime)\n",
    "print(dfERDTriggers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
